<?xml version="1.0" standalone="no"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg version="1.1" width="1200" height="534" onload="init(evt)" viewBox="0 0 1200 534" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><!--Flame graph stack visualization. See https://github.com/brendangregg/FlameGraph for latest version, and http://www.brendangregg.com/flamegraphs.html for examples.--><!--NOTES: --><defs><linearGradient id="background" y1="0" y2="1" x1="0" x2="0"><stop stop-color="#eeeeee" offset="5%"/><stop stop-color="#eeeeb0" offset="95%"/></linearGradient></defs><style type="text/css">
text { font-family:"Verdana"; font-size:12px; fill:rgb(0,0,0); }
#title { text-anchor:middle; font-size:17px; }
#search { opacity:0.1; cursor:pointer; }
#search:hover, #search.show { opacity:1; }
#subtitle { text-anchor:middle; font-color:rgb(160,160,160); }
#unzoom { cursor:pointer; }
#frames > *:hover { stroke:black; stroke-width:0.5; cursor:pointer; }
.hide { display:none; }
.parent { opacity:0.5; }
</style><script type="text/ecmascript"><![CDATA[var nametype = 'Function:';
var fontsize = 12;
var fontwidth = 0.59;
var xpad = 10;
var inverted = true;
var searchcolor = 'rgb(230,0,230)';
var fluiddrawing = true;]]><![CDATA["use strict";
var details, searchbtn, unzoombtn, matchedtxt, svg, searching, frames;
function init(evt) {
    details = document.getElementById("details").firstChild;
    searchbtn = document.getElementById("search");
    unzoombtn = document.getElementById("unzoom");
    matchedtxt = document.getElementById("matched");
    svg = document.getElementsByTagName("svg")[0];
    frames = document.getElementById("frames");
    searching = 0;

    // Use GET parameters to restore a flamegraph's state.
    var restore_state = function() {
        var params = get_params();
        if (params.x && params.y)
            zoom(find_group(document.querySelector('[x="' + params.x + '"][y="' + params.y + '"]')));
        if (params.s)
            search(params.s);
    };

    if (fluiddrawing) {
        // Make width dynamic so the SVG fits its parent's width.
        svg.removeAttribute("width");
        // Edge requires us to have a viewBox that gets updated with size changes.
        var isEdge = /Edge\/\d./i.test(navigator.userAgent);
        if (!isEdge) {
          svg.removeAttribute("viewBox");
        }
        var update_for_width_change = function() {
            if (isEdge) {
                svg.attributes.viewBox.value = "0 0 " + svg.width.baseVal.value + " " + svg.height.baseVal.value;
            }

            // Keep consistent padding on left and right of frames container.
            frames.attributes.width.value = svg.width.baseVal.value - xpad * 2;

            // Text truncation needs to be adjusted for the current width.
            var el = frames.children;
            for(var i = 0; i < el.length; i++) {
                update_text(el[i]);
            }

            // Keep search elements at a fixed distance from right edge.
            var svgWidth = svg.width.baseVal.value;
            searchbtn.attributes.x.value = svgWidth - xpad - 100;
            matchedtxt.attributes.x.value = svgWidth - xpad - 100;
        };
        window.addEventListener('resize', function() {
            update_for_width_change();
        });
        // This needs to be done asynchronously for Safari to work.
        setTimeout(function() {
            unzoom();
            update_for_width_change();
            restore_state();
        }, 0);
    } else {
        restore_state();
    }
}
// event listeners
window.addEventListener("click", function(e) {
    var target = find_group(e.target);
    if (target) {
        if (target.nodeName == "a") {
            if (e.ctrlKey === false) return;
            e.preventDefault();
        }
        if (target.classList.contains("parent")) unzoom();
        zoom(target);

        // set parameters for zoom state
        var el = target.querySelector("rect");
        if (el && el.attributes && el.attributes.y && el.attributes._orig_x) {
            var params = get_params()
            params.x = el.attributes._orig_x.value;
            params.y = el.attributes.y.value;
            history.replaceState(null, null, parse_params(params));
        }
    }
    else if (e.target.id == "unzoom") {
        unzoom();

        // remove zoom state
        var params = get_params();
        if (params.x) delete params.x;
        if (params.y) delete params.y;
        history.replaceState(null, null, parse_params(params));
    }
    else if (e.target.id == "search") search_prompt();
}, false)
// mouse-over for info
// show
window.addEventListener("mouseover", function(e) {
    var target = find_group(e.target);
    if (target) details.nodeValue = nametype + " " + g_to_text(target);
}, false)
// clear
window.addEventListener("mouseout", function(e) {
    var target = find_group(e.target);
    if (target) details.nodeValue = ' ';
}, false)
// ctrl-F for search
window.addEventListener("keydown",function (e) {
    if (e.keyCode === 114 || (e.ctrlKey && e.keyCode === 70)) {
        e.preventDefault();
        search_prompt();
    }
}, false)
// functions
function get_params() {
    var params = {};
    var paramsarr = window.location.search.substr(1).split('&');
    for (var i = 0; i < paramsarr.length; ++i) {
        var tmp = paramsarr[i].split("=");
        if (!tmp[0] || !tmp[1]) continue;
        params[tmp[0]]  = decodeURIComponent(tmp[1]);
    }
    return params;
}
function parse_params(params) {
    var uri = "?";
    for (var key in params) {
        uri += key + '=' + encodeURIComponent(params[key]) + '&';
    }
    if (uri.slice(-1) == "&")
        uri = uri.substring(0, uri.length - 1);
    if (uri == '?')
        uri = window.location.href.split('?')[0];
    return uri;
}
function find_child(node, selector) {
    var children = node.querySelectorAll(selector);
    if (children.length) return children[0];
    return;
}
function find_group(node) {
    var parent = node.parentElement;
    if (!parent) return;
    if (parent.id == "frames") return node;
    return find_group(parent);
}
function orig_save(e, attr, val) {
    if (e.attributes["_orig_" + attr] != undefined) return;
    if (e.attributes[attr] == undefined) return;
    if (val == undefined) val = e.attributes[attr].value;
    e.setAttribute("_orig_" + attr, val);
}
function orig_load(e, attr) {
    if (e.attributes["_orig_"+attr] == undefined) return;
    e.attributes[attr].value = e.attributes["_orig_" + attr].value;
    e.removeAttribute("_orig_" + attr);
}
function g_to_text(e) {
    var text = find_child(e, "title").firstChild.nodeValue;
    return (text)
}
function g_to_func(e) {
    var func = g_to_text(e);
    // if there's any manipulation we want to do to the function
    // name before it's searched, do it here before returning.
    return (func);
}
function update_text(e) {
    var r = find_child(e, "rect");
    var t = find_child(e, "text");
    var w = parseFloat(r.attributes.width.value) * frames.attributes.width.value / 100 - 3;
    var txt = find_child(e, "title").textContent.replace(/\([^(]*\)$/,"");
    t.attributes.x.value = format_percent((parseFloat(r.attributes.x.value) + (100 * 3 / frames.attributes.width.value)));
    // Smaller than this size won't fit anything
    if (w < 2 * fontsize * fontwidth) {
        t.textContent = "";
        return;
    }
    t.textContent = txt;
    // Fit in full text width
    if (/^ *\$/.test(txt) || t.getComputedTextLength() < w)
        return;
    for (var x = txt.length - 2; x > 0; x--) {
        if (t.getSubStringLength(0, x + 2) <= w) {
            t.textContent = txt.substring(0, x) + "..";
            return;
        }
    }
    t.textContent = "";
}
// zoom
function zoom_reset(e) {
    if (e.attributes != undefined) {
        orig_load(e, "x");
        orig_load(e, "width");
    }
    if (e.childNodes == undefined) return;
    for(var i = 0, c = e.childNodes; i < c.length; i++) {
        zoom_reset(c[i]);
    }
}
function zoom_child(e, x, ratio) {
    if (e.attributes != undefined) {
        if (e.attributes.x != undefined) {
            orig_save(e, "x");
            e.attributes.x.value = format_percent((parseFloat(e.attributes.x.value) - x) * ratio);
            if (e.tagName == "text") {
                e.attributes.x.value = format_percent(parseFloat(find_child(e.parentNode, "rect[x]").attributes.x.value) + (100 * 3 / frames.attributes.width.value));
            }
        }
        if (e.attributes.width != undefined) {
            orig_save(e, "width");
            e.attributes.width.value = format_percent(parseFloat(e.attributes.width.value) * ratio);
        }
    }
    if (e.childNodes == undefined) return;
    for(var i = 0, c = e.childNodes; i < c.length; i++) {
        zoom_child(c[i], x, ratio);
    }
}
function zoom_parent(e) {
    if (e.attributes) {
        if (e.attributes.x != undefined) {
            orig_save(e, "x");
            e.attributes.x.value = "0.0%";
        }
        if (e.attributes.width != undefined) {
            orig_save(e, "width");
            e.attributes.width.value = "100.0%";
        }
    }
    if (e.childNodes == undefined) return;
    for(var i = 0, c = e.childNodes; i < c.length; i++) {
        zoom_parent(c[i]);
    }
}
function zoom(node) {
    var attr = find_child(node, "rect").attributes;
    var width = parseFloat(attr.width.value);
    var xmin = parseFloat(attr.x.value);
    var xmax = xmin + width;
    var ymin = parseFloat(attr.y.value);
    var ratio = 100 / width;
    // XXX: Workaround for JavaScript float issues (fix me)
    var fudge = 0.001;
    unzoombtn.classList.remove("hide");
    var el = frames.children;
    for (var i = 0; i < el.length; i++) {
        var e = el[i];
        var a = find_child(e, "rect").attributes;
        var ex = parseFloat(a.x.value);
        var ew = parseFloat(a.width.value);
        // Is it an ancestor
        if (!inverted) {
            var upstack = parseFloat(a.y.value) > ymin;
        } else {
            var upstack = parseFloat(a.y.value) < ymin;
        }
        if (upstack) {
            // Direct ancestor
            if (ex <= xmin && (ex+ew+fudge) >= xmax) {
                e.classList.add("parent");
                zoom_parent(e);
                update_text(e);
            }
            // not in current path
            else
                e.classList.add("hide");
        }
        // Children maybe
        else {
            // no common path
            if (ex < xmin || ex + fudge >= xmax) {
                e.classList.add("hide");
            }
            else {
                zoom_child(e, xmin, ratio);
                update_text(e);
            }
        }
    }
}
function unzoom() {
    unzoombtn.classList.add("hide");
    var el = frames.children;
    for(var i = 0; i < el.length; i++) {
        el[i].classList.remove("parent");
        el[i].classList.remove("hide");
        zoom_reset(el[i]);
        update_text(el[i]);
    }
}
// search
function reset_search() {
    var el = document.querySelectorAll("#frames rect");
    for (var i = 0; i < el.length; i++) {
        orig_load(el[i], "fill")
    }
    var params = get_params();
    delete params.s;
    history.replaceState(null, null, parse_params(params));
}
function search_prompt() {
    if (!searching) {
        var term = prompt("Enter a search term (regexp " +
            "allowed, eg: ^ext4_)", "");
        if (term != null) {
            search(term)
        }
    } else {
        reset_search();
        searching = 0;
        searchbtn.classList.remove("show");
        searchbtn.firstChild.nodeValue = "Search"
        matchedtxt.classList.add("hide");
        matchedtxt.firstChild.nodeValue = ""
    }
}
function search(term) {
    var re = new RegExp(term);
    var el = frames.children;
    var matches = new Object();
    var maxwidth = 0;
    for (var i = 0; i < el.length; i++) {
        var e = el[i];
        var func = g_to_func(e);
        var rect = find_child(e, "rect");
        if (func == null || rect == null)
            continue;
        // Save max width. Only works as we have a root frame
        var w = parseFloat(rect.attributes.width.value);
        if (w > maxwidth)
            maxwidth = w;
        if (func.match(re)) {
            // highlight
            var x = parseFloat(rect.attributes.x.value);
            orig_save(rect, "fill");
            rect.attributes.fill.value = searchcolor;
            // remember matches
            if (matches[x] == undefined) {
                matches[x] = w;
            } else {
                if (w > matches[x]) {
                    // overwrite with parent
                    matches[x] = w;
                }
            }
            searching = 1;
        }
    }
    if (!searching)
        return;
    var params = get_params();
    params.s = term;
    history.replaceState(null, null, parse_params(params));

    searchbtn.classList.add("show");
    searchbtn.firstChild.nodeValue = "Reset Search";
    // calculate percent matched, excluding vertical overlap
    var count = 0;
    var lastx = -1;
    var lastw = 0;
    var keys = Array();
    for (k in matches) {
        if (matches.hasOwnProperty(k))
            keys.push(k);
    }
    // sort the matched frames by their x location
    // ascending, then width descending
    keys.sort(function(a, b){
        return a - b;
    });
    // Step through frames saving only the biggest bottom-up frames
    // thanks to the sort order. This relies on the tree property
    // where children are always smaller than their parents.
    var fudge = 0.0001;    // JavaScript floating point
    for (var k in keys) {
        var x = parseFloat(keys[k]);
        var w = matches[keys[k]];
        if (x >= lastx + lastw - fudge) {
            count += w;
            lastx = x;
            lastw = w;
        }
    }
    // display matched percent
    matchedtxt.classList.remove("hide");
    var pct = 100 * count / maxwidth;
    if (pct != 100) pct = pct.toFixed(1);
    matchedtxt.firstChild.nodeValue = "Matched: " + pct + "%";
}
function format_percent(n) {
    return n.toFixed(4) + "%";
}
]]></script><rect x="0" y="0" width="100%" height="534" fill="url(#background)"/><text id="title" x="50.0000%" y="24.00">py-spy</text><text id="details" x="10" y="517.00"> </text><text id="unzoom" class="hide" x="10" y="24.00">Reset Zoom</text><text id="search" x="1090" y="24.00">Search</text><text id="matched" x="1090" y="517.00"> </text><svg id="frames" x="10" width="1180"><g><title>_find_and_load_unlocked (&lt;frozen importlib._bootstrap&gt;:953) (8 samples, 1.18%)</title><rect x="1.0355%" y="180" width="1.1834%" height="15" fill="rgb(227,0,7)"/><text x="1.2855%" y="190.50"></text></g><g><title>_call_with_frames_removed (&lt;frozen importlib._bootstrap&gt;:219) (8 samples, 1.18%)</title><rect x="1.0355%" y="196" width="1.1834%" height="15" fill="rgb(217,0,24)"/><text x="1.2855%" y="206.50"></text></g><g><title>_find_and_load (&lt;frozen importlib._bootstrap&gt;:983) (8 samples, 1.18%)</title><rect x="1.0355%" y="212" width="1.1834%" height="15" fill="rgb(221,193,54)"/><text x="1.2855%" y="222.50"></text></g><g><title>_find_and_load_unlocked (&lt;frozen importlib._bootstrap&gt;:967) (8 samples, 1.18%)</title><rect x="1.0355%" y="228" width="1.1834%" height="15" fill="rgb(248,212,6)"/><text x="1.2855%" y="238.50"></text></g><g><title>_load_unlocked (&lt;frozen importlib._bootstrap&gt;:677) (8 samples, 1.18%)</title><rect x="1.0355%" y="244" width="1.1834%" height="15" fill="rgb(208,68,35)"/><text x="1.2855%" y="254.50"></text></g><g><title>exec_module (&lt;frozen importlib._bootstrap_external&gt;:728) (8 samples, 1.18%)</title><rect x="1.0355%" y="260" width="1.1834%" height="15" fill="rgb(232,128,0)"/><text x="1.2855%" y="270.50"></text></g><g><title>_call_with_frames_removed (&lt;frozen importlib._bootstrap&gt;:219) (8 samples, 1.18%)</title><rect x="1.0355%" y="276" width="1.1834%" height="15" fill="rgb(207,160,47)"/><text x="1.2855%" y="286.50"></text></g><g><title>&lt;module&gt; (sklearn/__init__.py:82) (8 samples, 1.18%)</title><rect x="1.0355%" y="292" width="1.1834%" height="15" fill="rgb(228,23,34)"/><text x="1.2855%" y="302.50"></text></g><g><title>_find_and_load (&lt;frozen importlib._bootstrap&gt;:983) (8 samples, 1.18%)</title><rect x="1.0355%" y="308" width="1.1834%" height="15" fill="rgb(218,30,26)"/><text x="1.2855%" y="318.50"></text></g><g><title>_find_and_load_unlocked (&lt;frozen importlib._bootstrap&gt;:967) (8 samples, 1.18%)</title><rect x="1.0355%" y="324" width="1.1834%" height="15" fill="rgb(220,122,19)"/><text x="1.2855%" y="334.50"></text></g><g><title>_load_unlocked (&lt;frozen importlib._bootstrap&gt;:677) (8 samples, 1.18%)</title><rect x="1.0355%" y="340" width="1.1834%" height="15" fill="rgb(250,228,42)"/><text x="1.2855%" y="350.50"></text></g><g><title>exec_module (&lt;frozen importlib._bootstrap_external&gt;:728) (8 samples, 1.18%)</title><rect x="1.0355%" y="356" width="1.1834%" height="15" fill="rgb(240,193,28)"/><text x="1.2855%" y="366.50"></text></g><g><title>_call_with_frames_removed (&lt;frozen importlib._bootstrap&gt;:219) (8 samples, 1.18%)</title><rect x="1.0355%" y="372" width="1.1834%" height="15" fill="rgb(216,20,37)"/><text x="1.2855%" y="382.50"></text></g><g><title>&lt;module&gt; (sklearn/base.py:20) (8 samples, 1.18%)</title><rect x="1.0355%" y="388" width="1.1834%" height="15" fill="rgb(206,188,39)"/><text x="1.2855%" y="398.50"></text></g><g><title>_find_and_load (&lt;frozen importlib._bootstrap&gt;:983) (8 samples, 1.18%)</title><rect x="1.0355%" y="404" width="1.1834%" height="15" fill="rgb(217,207,13)"/><text x="1.2855%" y="414.50"></text></g><g><title>_find_and_load_unlocked (&lt;frozen importlib._bootstrap&gt;:967) (8 samples, 1.18%)</title><rect x="1.0355%" y="420" width="1.1834%" height="15" fill="rgb(231,73,38)"/><text x="1.2855%" y="430.50"></text></g><g><title>_load_unlocked (&lt;frozen importlib._bootstrap&gt;:677) (8 samples, 1.18%)</title><rect x="1.0355%" y="436" width="1.1834%" height="15" fill="rgb(225,20,46)"/><text x="1.2855%" y="446.50"></text></g><g><title>exec_module (&lt;frozen importlib._bootstrap_external&gt;:728) (8 samples, 1.18%)</title><rect x="1.0355%" y="452" width="1.1834%" height="15" fill="rgb(210,31,41)"/><text x="1.2855%" y="462.50"></text></g><g><title>_call_with_frames_removed (&lt;frozen importlib._bootstrap&gt;:219) (8 samples, 1.18%)</title><rect x="1.0355%" y="468" width="1.1834%" height="15" fill="rgb(221,200,47)"/><text x="1.2855%" y="478.50"></text></g><g><title>&lt;module&gt; (profiles/benches/neural_network/MLPClassifier/bench_MLPClassifier_default_b_cl.py:4) (10 samples, 1.48%)</title><rect x="1.0355%" y="148" width="1.4793%" height="15" fill="rgb(226,26,5)"/><text x="1.2855%" y="158.50"></text></g><g><title>_find_and_load (&lt;frozen importlib._bootstrap&gt;:983) (10 samples, 1.48%)</title><rect x="1.0355%" y="164" width="1.4793%" height="15" fill="rgb(249,33,26)"/><text x="1.2855%" y="174.50"></text></g><g><title>&lt;module&gt; (bench_MLPClassifier_default_b_cl_1000_50_12_float_.py:4) (23 samples, 3.40%)</title><rect x="0.0000%" y="52" width="3.4024%" height="15" fill="rgb(235,183,28)"/><text x="0.2500%" y="62.50">&lt;mo..</text></g><g><title>_find_and_load (&lt;frozen importlib._bootstrap&gt;:983) (23 samples, 3.40%)</title><rect x="0.0000%" y="68" width="3.4024%" height="15" fill="rgb(221,5,38)"/><text x="0.2500%" y="78.50">_fi..</text></g><g><title>_find_and_load_unlocked (&lt;frozen importlib._bootstrap&gt;:967) (23 samples, 3.40%)</title><rect x="0.0000%" y="84" width="3.4024%" height="15" fill="rgb(247,18,42)"/><text x="0.2500%" y="94.50">_fi..</text></g><g><title>_load_unlocked (&lt;frozen importlib._bootstrap&gt;:677) (23 samples, 3.40%)</title><rect x="0.0000%" y="100" width="3.4024%" height="15" fill="rgb(241,131,45)"/><text x="0.2500%" y="110.50">_lo..</text></g><g><title>exec_module (&lt;frozen importlib._bootstrap_external&gt;:728) (23 samples, 3.40%)</title><rect x="0.0000%" y="116" width="3.4024%" height="15" fill="rgb(249,31,29)"/><text x="0.2500%" y="126.50">exe..</text></g><g><title>_call_with_frames_removed (&lt;frozen importlib._bootstrap&gt;:219) (23 samples, 3.40%)</title><rect x="0.0000%" y="132" width="3.4024%" height="15" fill="rgb(225,111,53)"/><text x="0.2500%" y="142.50">_ca..</text></g><g><title>_predict (sklearn/neural_network/_multilayer_perceptron.py:667) (12 samples, 1.78%)</title><rect x="4.2899%" y="164" width="1.7751%" height="15" fill="rgb(238,160,17)"/><text x="4.5399%" y="174.50">_..</text></g><g><title>dgemm_beta_SANDYBRIDGE (libopenblasp-r0-34a18dc3.3.7.so) (8 samples, 1.18%)</title><rect x="6.3609%" y="212" width="1.1834%" height="15" fill="rgb(214,148,48)"/><text x="6.6109%" y="222.50"></text></g><g><title>dgemm_kernel_SANDYBRIDGE (libopenblasp-r0-34a18dc3.3.7.so) (41 samples, 6.07%)</title><rect x="7.5444%" y="212" width="6.0651%" height="15" fill="rgb(232,36,49)"/><text x="7.7944%" y="222.50">dgemm_ke..</text></g><g><title>PyUFunc_GeneralizedFunction (ufunc_object.c:2871) (14 samples, 2.07%)</title><rect x="13.6095%" y="244" width="2.0710%" height="15" fill="rgb(209,103,24)"/><text x="13.8595%" y="254.50">P..</text></g><g><title>NpyIter_AdvancedNew (nditer_constr.c:403) (13 samples, 1.92%)</title><rect x="13.7574%" y="260" width="1.9231%" height="15" fill="rgb(229,88,8)"/><text x="14.0074%" y="270.50">N..</text></g><g><title>npyiter_allocate_arrays (nditer_constr.c:2942) (13 samples, 1.92%)</title><rect x="13.7574%" y="276" width="1.9231%" height="15" fill="rgb(213,181,19)"/><text x="14.0074%" y="286.50">n..</text></g><g><title>PyArray_AssignArray (array_assign_array.c:404) (13 samples, 1.92%)</title><rect x="13.7574%" y="292" width="1.9231%" height="15" fill="rgb(254,191,54)"/><text x="14.0074%" y="302.50">P..</text></g><g><title>raw_array_assign_array (array_assign_array.c:137) (12 samples, 1.78%)</title><rect x="13.9053%" y="308" width="1.7751%" height="15" fill="rgb(241,83,37)"/><text x="14.1553%" y="318.50">r..</text></g><g><title>_aligned_contig_cast_float_to_double (lowlevel_strided_loops.c.src:855) (12 samples, 1.78%)</title><rect x="13.9053%" y="324" width="1.7751%" height="15" fill="rgb(233,36,39)"/><text x="14.1553%" y="334.50">_..</text></g><g><title>exec_blas_async_wait (libopenblasp-r0-34a18dc3.3.7.so) (29 samples, 4.29%)</title><rect x="16.2722%" y="340" width="4.2899%" height="15" fill="rgb(226,3,54)"/><text x="16.5222%" y="350.50">exec_..</text></g><g><title>sched_yield (libc-2.29.so) (29 samples, 4.29%)</title><rect x="16.2722%" y="356" width="4.2899%" height="15" fill="rgb(245,192,40)"/><text x="16.5222%" y="366.50">sched..</text></g><g><title>_forward_pass (sklearn/neural_network/_multilayer_perceptron.py:104) (100 samples, 14.79%)</title><rect x="6.3609%" y="180" width="14.7929%" height="15" fill="rgb(238,167,29)"/><text x="6.6109%" y="190.50">_forward_pass (sklearn/..</text></g><g><title>safe_sparse_dot (sklearn/utils/extmath.py:151) (100 samples, 14.79%)</title><rect x="6.3609%" y="196" width="14.7929%" height="15" fill="rgb(232,182,51)"/><text x="6.6109%" y="206.50">safe_sparse_dot (sklear..</text></g><g><title>ufunc_generic_call (ufunc_object.c:4725) (51 samples, 7.54%)</title><rect x="13.6095%" y="212" width="7.5444%" height="15" fill="rgb(231,60,39)"/><text x="13.8595%" y="222.50">ufunc_gene..</text></g><g><title>PyUFunc_GenericFunction (ufunc_object.c:3142) (51 samples, 7.54%)</title><rect x="13.6095%" y="228" width="7.5444%" height="15" fill="rgb(208,69,12)"/><text x="13.8595%" y="238.50">PyUFunc_Ge..</text></g><g><title>PyUFunc_GeneralizedFunction (ufunc_object.c:3008) (36 samples, 5.33%)</title><rect x="15.8284%" y="244" width="5.3254%" height="15" fill="rgb(235,93,37)"/><text x="16.0784%" y="254.50">PyUFunc..</text></g><g><title>DOUBLE_matmul (matmul.c.src:471) (36 samples, 5.33%)</title><rect x="15.8284%" y="260" width="5.3254%" height="15" fill="rgb(213,116,39)"/><text x="16.0784%" y="270.50">DOUBLE_..</text></g><g><title>cblas_dgemm (libopenblasp-r0-34a18dc3.3.7.so) (36 samples, 5.33%)</title><rect x="15.8284%" y="276" width="5.3254%" height="15" fill="rgb(222,207,29)"/><text x="16.0784%" y="286.50">cblas_d..</text></g><g><title>dgemm_thread_nn (libopenblasp-r0-34a18dc3.3.7.so) (35 samples, 5.18%)</title><rect x="15.9763%" y="292" width="5.1775%" height="15" fill="rgb(206,96,30)"/><text x="16.2263%" y="302.50">dgemm_..</text></g><g><title>gemm_driver (libopenblasp-r0-34a18dc3.3.7.so) (35 samples, 5.18%)</title><rect x="15.9763%" y="308" width="5.1775%" height="15" fill="rgb(218,138,4)"/><text x="16.2263%" y="318.50">gemm_d..</text></g><g><title>exec_blas (libopenblasp-r0-34a18dc3.3.7.so) (35 samples, 5.18%)</title><rect x="15.9763%" y="324" width="5.1775%" height="15" fill="rgb(250,191,14)"/><text x="16.2263%" y="334.50">exec_b..</text></g><g><title>DOUBLE_add (loops.c.src:1760) (11 samples, 1.63%)</title><rect x="21.1538%" y="260" width="1.6272%" height="15" fill="rgb(239,60,40)"/><text x="21.4038%" y="270.50"></text></g><g><title>run_binary_simd_add_DOUBLE (simd.inc.src:250) (11 samples, 1.63%)</title><rect x="21.1538%" y="276" width="1.6272%" height="15" fill="rgb(206,27,48)"/><text x="21.4038%" y="286.50"></text></g><g><title>sse2_binary_add_DOUBLE (simd.inc.src:604) (7 samples, 1.04%)</title><rect x="21.7456%" y="292" width="1.0355%" height="15" fill="rgb(225,35,8)"/><text x="21.9956%" y="302.50"></text></g><g><title>_mm_store_pd (emmintrin.h:147) (7 samples, 1.04%)</title><rect x="21.7456%" y="308" width="1.0355%" height="15" fill="rgb(250,213,24)"/><text x="21.9956%" y="318.50"></text></g><g><title>_forward_pass (sklearn/neural_network/_multilayer_perceptron.py:105) (15 samples, 2.22%)</title><rect x="21.1538%" y="180" width="2.2189%" height="15" fill="rgb(247,123,22)"/><text x="21.4038%" y="190.50">_..</text></g><g><title>ufunc_generic_call (ufunc_object.c:4725) (15 samples, 2.22%)</title><rect x="21.1538%" y="196" width="2.2189%" height="15" fill="rgb(231,138,38)"/><text x="21.4038%" y="206.50">u..</text></g><g><title>PyUFunc_GenericFunction (ufunc_object.c:3262) (15 samples, 2.22%)</title><rect x="21.1538%" y="212" width="2.2189%" height="15" fill="rgb(231,145,46)"/><text x="21.4038%" y="222.50">P..</text></g><g><title>execute_legacy_ufunc_loop (ufunc_object.c:1742) (15 samples, 2.22%)</title><rect x="21.1538%" y="228" width="2.2189%" height="15" fill="rgb(251,118,11)"/><text x="21.4038%" y="238.50">e..</text></g><g><title>iterator_loop (ufunc_object.c:1582) (15 samples, 2.22%)</title><rect x="21.1538%" y="244" width="2.2189%" height="15" fill="rgb(217,147,25)"/><text x="21.4038%" y="254.50">i..</text></g><g><title>DOUBLE_clip (clip.c.src:96) (11 samples, 1.63%)</title><rect x="25.2959%" y="404" width="1.6272%" height="15" fill="rgb(247,81,37)"/><text x="25.5459%" y="414.50"></text></g><g><title>_forward_pass (sklearn/neural_network/_multilayer_perceptron.py:109) (55 samples, 8.14%)</title><rect x="23.3728%" y="180" width="8.1361%" height="15" fill="rgb(209,12,38)"/><text x="23.6228%" y="190.50">_forward_pa..</text></g><g><title>relu (sklearn/neural_network/_base.py:75) (55 samples, 8.14%)</title><rect x="23.3728%" y="196" width="8.1361%" height="15" fill="rgb(227,1,9)"/><text x="23.6228%" y="206.50">relu (sklea..</text></g><g><title>clip (&lt;__array_function__ internals&gt;:6) (55 samples, 8.14%)</title><rect x="23.3728%" y="212" width="8.1361%" height="15" fill="rgb(248,47,43)"/><text x="23.6228%" y="222.50">clip (&lt;__ar..</text></g><g><title>array_implement_array_function (arrayfunction_override.c:259) (55 samples, 8.14%)</title><rect x="23.3728%" y="228" width="8.1361%" height="15" fill="rgb(221,10,30)"/><text x="23.6228%" y="238.50">array_imple..</text></g><g><title>clip (numpy/core/fromnumeric.py:2037) (54 samples, 7.99%)</title><rect x="23.5207%" y="244" width="7.9882%" height="15" fill="rgb(210,229,1)"/><text x="23.7707%" y="254.50">clip (numpy..</text></g><g><title>_wrapfunc (numpy/core/fromnumeric.py:61) (51 samples, 7.54%)</title><rect x="23.9645%" y="260" width="7.5444%" height="15" fill="rgb(222,148,37)"/><text x="24.2145%" y="270.50">_wrapfunc ..</text></g><g><title>array_clip (methods.c:2381) (51 samples, 7.54%)</title><rect x="23.9645%" y="276" width="7.5444%" height="15" fill="rgb(234,67,33)"/><text x="24.2145%" y="286.50">array_clip..</text></g><g><title>forward_ndarray_method (methods.c:108) (51 samples, 7.54%)</title><rect x="23.9645%" y="292" width="7.5444%" height="15" fill="rgb(247,98,35)"/><text x="24.2145%" y="302.50">forward_nd..</text></g><g><title>_clip (numpy/core/_methods.py:132) (44 samples, 6.51%)</title><rect x="25.0000%" y="308" width="6.5089%" height="15" fill="rgb(247,138,52)"/><text x="25.2500%" y="318.50">_clip (nu..</text></g><g><title>_clip_dep_invoke_with_casting (numpy/core/_methods.py:85) (44 samples, 6.51%)</title><rect x="25.0000%" y="324" width="6.5089%" height="15" fill="rgb(213,79,30)"/><text x="25.2500%" y="334.50">_clip_dep..</text></g><g><title>ufunc_generic_call (ufunc_object.c:4725) (44 samples, 6.51%)</title><rect x="25.0000%" y="340" width="6.5089%" height="15" fill="rgb(246,177,23)"/><text x="25.2500%" y="350.50">ufunc_gen..</text></g><g><title>PyUFunc_GenericFunction (ufunc_object.c:3262) (42 samples, 6.21%)</title><rect x="25.2959%" y="356" width="6.2130%" height="15" fill="rgb(230,62,27)"/><text x="25.5459%" y="366.50">PyUFunc_..</text></g><g><title>execute_legacy_ufunc_loop (ufunc_object.c:1742) (42 samples, 6.21%)</title><rect x="25.2959%" y="372" width="6.2130%" height="15" fill="rgb(216,154,8)"/><text x="25.5459%" y="382.50">execute_..</text></g><g><title>iterator_loop (ufunc_object.c:1582) (42 samples, 6.21%)</title><rect x="25.2959%" y="388" width="6.2130%" height="15" fill="rgb(244,35,45)"/><text x="25.5459%" y="398.50">iterator..</text></g><g><title>DOUBLE_clip (clip.c.src:97) (31 samples, 4.59%)</title><rect x="26.9231%" y="404" width="4.5858%" height="15" fill="rgb(251,115,12)"/><text x="27.1731%" y="414.50">DOUBL..</text></g><g><title>softmax (sklearn/neural_network/_base.py:93) (14 samples, 2.07%)</title><rect x="32.5444%" y="196" width="2.0710%" height="15" fill="rgb(240,54,50)"/><text x="32.7944%" y="206.50">s..</text></g><g><title>ufunc_generic_call (ufunc_object.c:4725) (12 samples, 1.78%)</title><rect x="32.8402%" y="212" width="1.7751%" height="15" fill="rgb(233,84,52)"/><text x="33.0902%" y="222.50">u..</text></g><g><title>PyUFunc_GenericFunction (ufunc_object.c:3262) (12 samples, 1.78%)</title><rect x="32.8402%" y="228" width="1.7751%" height="15" fill="rgb(207,117,47)"/><text x="33.0902%" y="238.50">P..</text></g><g><title>execute_legacy_ufunc_loop (ufunc_object.c:1670) (12 samples, 1.78%)</title><rect x="32.8402%" y="244" width="1.7751%" height="15" fill="rgb(249,43,39)"/><text x="33.0902%" y="254.50">e..</text></g><g><title>trivial_two_operand_loop (ufunc_object.c:1354) (12 samples, 1.78%)</title><rect x="32.8402%" y="260" width="1.7751%" height="15" fill="rgb(209,38,44)"/><text x="33.0902%" y="270.50">t..</text></g><g><title>PyUFunc_d_d (loops.c.src:190) (9 samples, 1.33%)</title><rect x="33.2840%" y="276" width="1.3314%" height="15" fill="rgb(236,212,23)"/><text x="33.5340%" y="286.50"></text></g><g><title>exp (libm-2.29.so) (9 samples, 1.33%)</title><rect x="33.2840%" y="292" width="1.3314%" height="15" fill="rgb(242,79,21)"/><text x="33.5340%" y="302.50"></text></g><g><title>array_sum (methods.c:2215) (9 samples, 1.33%)</title><rect x="34.6154%" y="212" width="1.3314%" height="15" fill="rgb(211,96,35)"/><text x="34.8654%" y="222.50"></text></g><g><title>forward_ndarray_method (methods.c:108) (9 samples, 1.33%)</title><rect x="34.6154%" y="228" width="1.3314%" height="15" fill="rgb(253,215,40)"/><text x="34.8654%" y="238.50"></text></g><g><title>_sum (numpy/core/_methods.py:38) (9 samples, 1.33%)</title><rect x="34.6154%" y="244" width="1.3314%" height="15" fill="rgb(211,81,21)"/><text x="34.8654%" y="254.50"></text></g><g><title>ufunc_reduce (ufunc_object.c:5521) (8 samples, 1.18%)</title><rect x="34.7633%" y="260" width="1.1834%" height="15" fill="rgb(208,190,38)"/><text x="35.0133%" y="270.50"></text></g><g><title>PyUFunc_GenericReduction (ufunc_object.c:4632) (8 samples, 1.18%)</title><rect x="34.7633%" y="276" width="1.1834%" height="15" fill="rgb(235,213,38)"/><text x="35.0133%" y="286.50"></text></g><g><title>PyUFunc_Reduce (ufunc_object.c:3671) (8 samples, 1.18%)</title><rect x="34.7633%" y="292" width="1.1834%" height="15" fill="rgb(237,122,38)"/><text x="35.0133%" y="302.50"></text></g><g><title>PyUFunc_ReduceWrapper (reduction.c:575) (7 samples, 1.04%)</title><rect x="34.9112%" y="308" width="1.0355%" height="15" fill="rgb(244,218,35)"/><text x="35.1612%" y="318.50"></text></g><g><title>reduce_loop (ufunc_object.c:3569) (7 samples, 1.04%)</title><rect x="34.9112%" y="324" width="1.0355%" height="15" fill="rgb(240,68,47)"/><text x="35.1612%" y="334.50"></text></g><g><title>&lt;module&gt; (bench_MLPClassifier_default_b_cl_1000_50_12_float_.py:54) (217 samples, 32.10%)</title><rect x="3.9941%" y="52" width="32.1006%" height="15" fill="rgb(210,16,53)"/><text x="4.2441%" y="62.50">&lt;module&gt; (bench_MLPClassifier_default_b_cl_1000_50_1..</text></g><g><title>profile_skl (bench_MLPClassifier_default_b_cl_1000_50_12_float_.py:53) (217 samples, 32.10%)</title><rect x="3.9941%" y="68" width="32.1006%" height="15" fill="rgb(235,124,12)"/><text x="4.2441%" y="78.50">profile_skl (bench_MLPClassifier_default_b_cl_1000_5..</text></g><g><title>setup_profile (bench_MLPClassifier_default_b_cl_1000_50_12_float_.py:37) (217 samples, 32.10%)</title><rect x="3.9941%" y="84" width="32.1006%" height="15" fill="rgb(224,169,11)"/><text x="4.2441%" y="94.50">setup_profile (bench_MLPClassifier_default_b_cl_1000..</text></g><g><title>profile (bench_MLPClassifier_default_b_cl_1000_50_12_float_.py:31) (217 samples, 32.10%)</title><rect x="3.9941%" y="100" width="32.1006%" height="15" fill="rgb(250,166,2)"/><text x="4.2441%" y="110.50">profile (bench_MLPClassifier_default_b_cl_1000_50_12..</text></g><g><title>time_predict (mlprodict/asv_benchmark/common_asv_skl.py:182) (217 samples, 32.10%)</title><rect x="3.9941%" y="116" width="32.1006%" height="15" fill="rgb(242,216,29)"/><text x="4.2441%" y="126.50">time_predict (mlprodict/asv_benchmark/common_asv_skl..</text></g><g><title>&lt;lambda&gt; (mlprodict/asv_benchmark/common_asv_skl.py:228) (217 samples, 32.10%)</title><rect x="3.9941%" y="132" width="32.1006%" height="15" fill="rgb(230,116,27)"/><text x="4.2441%" y="142.50">&lt;lambda&gt; (mlprodict/asv_benchmark/common_asv_skl.py:..</text></g><g><title>predict_proba (sklearn/neural_network/_multilayer_perceptron.py:1072) (215 samples, 31.80%)</title><rect x="4.2899%" y="148" width="31.8047%" height="15" fill="rgb(228,99,48)"/><text x="4.5399%" y="158.50">predict_proba (sklearn/neural_network/_multilayer_p..</text></g><g><title>_predict (sklearn/neural_network/_multilayer_perceptron.py:685) (202 samples, 29.88%)</title><rect x="6.2130%" y="164" width="29.8817%" height="15" fill="rgb(253,11,6)"/><text x="6.4630%" y="174.50">_predict (sklearn/neural_network/_multilayer_per..</text></g><g><title>_forward_pass (sklearn/neural_network/_multilayer_perceptron.py:113) (31 samples, 4.59%)</title><rect x="31.5089%" y="180" width="4.5858%" height="15" fill="rgb(247,143,39)"/><text x="31.7589%" y="190.50">_forw..</text></g><g><title>softmax (sklearn/neural_network/_base.py:94) (10 samples, 1.48%)</title><rect x="34.6154%" y="196" width="1.4793%" height="15" fill="rgb(236,97,10)"/><text x="34.8654%" y="206.50"></text></g><g><title>exec_blas_async_wait (libopenblasp-r0-34a18dc3.3.7.so) (24 samples, 3.55%)</title><rect x="37.5740%" y="388" width="3.5503%" height="15" fill="rgb(233,208,19)"/><text x="37.8240%" y="398.50">exec..</text></g><g><title>sched_yield (libc-2.29.so) (24 samples, 3.55%)</title><rect x="37.5740%" y="404" width="3.5503%" height="15" fill="rgb(216,164,2)"/><text x="37.8240%" y="414.50">sche..</text></g><g><title>array_implement_array_function (arrayfunction_override.c:259) (36 samples, 5.33%)</title><rect x="36.6864%" y="244" width="5.3254%" height="15" fill="rgb(220,129,5)"/><text x="36.9364%" y="254.50">array_i..</text></g><g><title>array_matrixproduct (multiarraymodule.c:2232) (36 samples, 5.33%)</title><rect x="36.6864%" y="260" width="5.3254%" height="15" fill="rgb(242,17,10)"/><text x="36.9364%" y="270.50">array_m..</text></g><g><title>PyArray_MatrixProduct2 (multiarraymodule.c:958) (36 samples, 5.33%)</title><rect x="36.6864%" y="276" width="5.3254%" height="15" fill="rgb(242,107,0)"/><text x="36.9364%" y="286.50">PyArray..</text></g><g><title>cblas_matrixproduct (cblasfuncs.c:674) (31 samples, 4.59%)</title><rect x="37.4260%" y="292" width="4.5858%" height="15" fill="rgb(251,28,31)"/><text x="37.6760%" y="302.50">cblas..</text></g><g><title>gemm (cblasfuncs.c:40) (31 samples, 4.59%)</title><rect x="37.4260%" y="308" width="4.5858%" height="15" fill="rgb(233,223,10)"/><text x="37.6760%" y="318.50">gemm ..</text></g><g><title>cblas_sgemm (libopenblasp-r0-34a18dc3.3.7.so) (31 samples, 4.59%)</title><rect x="37.4260%" y="324" width="4.5858%" height="15" fill="rgb(215,21,27)"/><text x="37.6760%" y="334.50">cblas..</text></g><g><title>sgemm_thread_nn (libopenblasp-r0-34a18dc3.3.7.so) (31 samples, 4.59%)</title><rect x="37.4260%" y="340" width="4.5858%" height="15" fill="rgb(232,23,21)"/><text x="37.6760%" y="350.50">sgemm..</text></g><g><title>gemm_driver (libopenblasp-r0-34a18dc3.3.7.so) (31 samples, 4.59%)</title><rect x="37.4260%" y="356" width="4.5858%" height="15" fill="rgb(244,5,23)"/><text x="37.6760%" y="366.50">gemm_..</text></g><g><title>exec_blas (libopenblasp-r0-34a18dc3.3.7.so) (31 samples, 4.59%)</title><rect x="37.4260%" y="372" width="4.5858%" height="15" fill="rgb(226,81,46)"/><text x="37.6760%" y="382.50">exec_..</text></g><g><title>compiled_run (&lt;string&gt;:11) (70 samples, 10.36%)</title><rect x="36.6864%" y="180" width="10.3550%" height="15" fill="rgb(247,70,30)"/><text x="36.9364%" y="190.50">compiled_run (&lt;..</text></g><g><title>_run (mlprodict/onnxrt/ops_cpu/op_matmul.py:17) (70 samples, 10.36%)</title><rect x="36.6864%" y="196" width="10.3550%" height="15" fill="rgb(212,68,19)"/><text x="36.9364%" y="206.50">_run (mlprodict..</text></g><g><title>numpy_dot_inplace (mlprodict/onnxrt/ops_cpu/_op_numpy_helper.py:16) (70 samples, 10.36%)</title><rect x="36.6864%" y="212" width="10.3550%" height="15" fill="rgb(240,187,13)"/><text x="36.9364%" y="222.50">numpy_dot_inpla..</text></g><g><title>dot (&lt;__array_function__ internals&gt;:6) (70 samples, 10.36%)</title><rect x="36.6864%" y="228" width="10.3550%" height="15" fill="rgb(223,113,26)"/><text x="36.9364%" y="238.50">dot (&lt;__array_f..</text></g><g><title>sgemm_kernel_SANDYBRIDGE (libopenblasp-r0-34a18dc3.3.7.so) (30 samples, 4.44%)</title><rect x="42.6036%" y="244" width="4.4379%" height="15" fill="rgb(206,192,2)"/><text x="42.8536%" y="254.50">sgemm..</text></g><g><title>FLOAT_maximum (loops.c.src:1872) (15 samples, 2.22%)</title><rect x="47.1893%" y="276" width="2.2189%" height="15" fill="rgb(241,108,4)"/><text x="47.4393%" y="286.50">F..</text></g><g><title>FLOAT_maximum (loops.c.src:1876) (18 samples, 2.66%)</title><rect x="50.1479%" y="276" width="2.6627%" height="15" fill="rgb(247,173,49)"/><text x="50.3979%" y="286.50">FL..</text></g><g><title>compiled_run (&lt;string&gt;:13) (42 samples, 6.21%)</title><rect x="47.0414%" y="180" width="6.2130%" height="15" fill="rgb(224,114,35)"/><text x="47.2914%" y="190.50">compiled..</text></g><g><title>_run (mlprodict/onnxrt/ops_cpu/op_relu.py:20) (42 samples, 6.21%)</title><rect x="47.0414%" y="196" width="6.2130%" height="15" fill="rgb(245,159,27)"/><text x="47.2914%" y="206.50">_run (ml..</text></g><g><title>ufunc_generic_call (ufunc_object.c:4725) (42 samples, 6.21%)</title><rect x="47.0414%" y="212" width="6.2130%" height="15" fill="rgb(245,172,44)"/><text x="47.2914%" y="222.50">ufunc_ge..</text></g><g><title>PyUFunc_GenericFunction (ufunc_object.c:3262) (41 samples, 6.07%)</title><rect x="47.1893%" y="228" width="6.0651%" height="15" fill="rgb(236,23,11)"/><text x="47.4393%" y="238.50">PyUFunc_..</text></g><g><title>execute_legacy_ufunc_loop (ufunc_object.c:1731) (41 samples, 6.07%)</title><rect x="47.1893%" y="244" width="6.0651%" height="15" fill="rgb(205,117,38)"/><text x="47.4393%" y="254.50">execute_..</text></g><g><title>trivial_three_operand_loop (ufunc_object.c:1385) (41 samples, 6.07%)</title><rect x="47.1893%" y="260" width="6.0651%" height="15" fill="rgb(237,72,25)"/><text x="47.4393%" y="270.50">trivial_..</text></g><g><title>exec_blas_async_wait (libopenblasp-r0-34a18dc3.3.7.so) (18 samples, 2.66%)</title><rect x="53.4024%" y="388" width="2.6627%" height="15" fill="rgb(244,70,9)"/><text x="53.6524%" y="398.50">ex..</text></g><g><title>sched_yield (libc-2.29.so) (18 samples, 2.66%)</title><rect x="53.4024%" y="404" width="2.6627%" height="15" fill="rgb(217,125,39)"/><text x="53.6524%" y="414.50">sc..</text></g><g><title>array_implement_array_function (arrayfunction_override.c:259) (25 samples, 3.70%)</title><rect x="53.4024%" y="244" width="3.6982%" height="15" fill="rgb(235,36,10)"/><text x="53.6524%" y="254.50">arra..</text></g><g><title>array_matrixproduct (multiarraymodule.c:2232) (25 samples, 3.70%)</title><rect x="53.4024%" y="260" width="3.6982%" height="15" fill="rgb(251,123,47)"/><text x="53.6524%" y="270.50">arra..</text></g><g><title>PyArray_MatrixProduct2 (multiarraymodule.c:958) (25 samples, 3.70%)</title><rect x="53.4024%" y="276" width="3.6982%" height="15" fill="rgb(221,13,13)"/><text x="53.6524%" y="286.50">PyAr..</text></g><g><title>cblas_matrixproduct (cblasfuncs.c:674) (25 samples, 3.70%)</title><rect x="53.4024%" y="292" width="3.6982%" height="15" fill="rgb(238,131,9)"/><text x="53.6524%" y="302.50">cbla..</text></g><g><title>gemm (cblasfuncs.c:40) (25 samples, 3.70%)</title><rect x="53.4024%" y="308" width="3.6982%" height="15" fill="rgb(211,50,8)"/><text x="53.6524%" y="318.50">gemm..</text></g><g><title>cblas_sgemm (libopenblasp-r0-34a18dc3.3.7.so) (25 samples, 3.70%)</title><rect x="53.4024%" y="324" width="3.6982%" height="15" fill="rgb(245,182,24)"/><text x="53.6524%" y="334.50">cbla..</text></g><g><title>sgemm_thread_nn (libopenblasp-r0-34a18dc3.3.7.so) (25 samples, 3.70%)</title><rect x="53.4024%" y="340" width="3.6982%" height="15" fill="rgb(242,14,37)"/><text x="53.6524%" y="350.50">sgem..</text></g><g><title>gemm_driver (libopenblasp-r0-34a18dc3.3.7.so) (25 samples, 3.70%)</title><rect x="53.4024%" y="356" width="3.6982%" height="15" fill="rgb(246,228,12)"/><text x="53.6524%" y="366.50">gemm..</text></g><g><title>exec_blas (libopenblasp-r0-34a18dc3.3.7.so) (25 samples, 3.70%)</title><rect x="53.4024%" y="372" width="3.6982%" height="15" fill="rgb(213,55,15)"/><text x="53.6524%" y="382.50">exec..</text></g><g><title>inner_thread (libopenblasp-r0-34a18dc3.3.7.so) (7 samples, 1.04%)</title><rect x="56.0651%" y="388" width="1.0355%" height="15" fill="rgb(209,9,3)"/><text x="56.3151%" y="398.50"></text></g><g><title>sgemm_oncopy_SANDYBRIDGE (libopenblasp-r0-34a18dc3.3.7.so) (7 samples, 1.04%)</title><rect x="56.0651%" y="404" width="1.0355%" height="15" fill="rgb(230,59,30)"/><text x="56.3151%" y="414.50"></text></g><g><title>compiled_run (&lt;string&gt;:14) (34 samples, 5.03%)</title><rect x="53.2544%" y="180" width="5.0296%" height="15" fill="rgb(209,121,21)"/><text x="53.5044%" y="190.50">compil..</text></g><g><title>_run (mlprodict/onnxrt/ops_cpu/op_matmul.py:17) (33 samples, 4.88%)</title><rect x="53.4024%" y="196" width="4.8817%" height="15" fill="rgb(220,109,13)"/><text x="53.6524%" y="206.50">_run (..</text></g><g><title>numpy_dot_inplace (mlprodict/onnxrt/ops_cpu/_op_numpy_helper.py:16) (33 samples, 4.88%)</title><rect x="53.4024%" y="212" width="4.8817%" height="15" fill="rgb(232,18,1)"/><text x="53.6524%" y="222.50">numpy_..</text></g><g><title>dot (&lt;__array_function__ internals&gt;:6) (33 samples, 4.88%)</title><rect x="53.4024%" y="228" width="4.8817%" height="15" fill="rgb(215,41,42)"/><text x="53.6524%" y="238.50">dot (&lt;..</text></g><g><title>sgemm_kernel_SANDYBRIDGE (libopenblasp-r0-34a18dc3.3.7.so) (8 samples, 1.18%)</title><rect x="57.1006%" y="244" width="1.1834%" height="15" fill="rgb(224,123,36)"/><text x="57.3506%" y="254.50"></text></g><g><title>ufunc_generic_call (ufunc_object.c:4725) (8 samples, 1.18%)</title><rect x="59.0237%" y="212" width="1.1834%" height="15" fill="rgb(240,125,3)"/><text x="59.2737%" y="222.50"></text></g><g><title>PyUFunc_GenericFunction (ufunc_object.c:3262) (8 samples, 1.18%)</title><rect x="59.0237%" y="228" width="1.1834%" height="15" fill="rgb(205,98,50)"/><text x="59.2737%" y="238.50"></text></g><g><title>execute_legacy_ufunc_loop (ufunc_object.c:1670) (8 samples, 1.18%)</title><rect x="59.0237%" y="244" width="1.1834%" height="15" fill="rgb(205,185,37)"/><text x="59.2737%" y="254.50"></text></g><g><title>trivial_two_operand_loop (ufunc_object.c:1354) (8 samples, 1.18%)</title><rect x="59.0237%" y="260" width="1.1834%" height="15" fill="rgb(238,207,15)"/><text x="59.2737%" y="270.50"></text></g><g><title>FLOAT_exp (loops.c.src:1607) (8 samples, 1.18%)</title><rect x="59.0237%" y="276" width="1.1834%" height="15" fill="rgb(213,199,42)"/><text x="59.2737%" y="286.50"></text></g><g><title>expf (libm-2.29.so) (7 samples, 1.04%)</title><rect x="59.1716%" y="292" width="1.0355%" height="15" fill="rgb(235,201,11)"/><text x="59.4216%" y="302.50"></text></g><g><title>_run (mlprodict/onnxrt/ops_cpu/op_softmax.py:24) (9 samples, 1.33%)</title><rect x="59.0237%" y="196" width="1.3314%" height="15" fill="rgb(207,46,11)"/><text x="59.2737%" y="206.50"></text></g><g><title>compiled_run (&lt;string&gt;:16) (23 samples, 3.40%)</title><rect x="58.2840%" y="180" width="3.4024%" height="15" fill="rgb(241,35,35)"/><text x="58.5340%" y="190.50">com..</text></g><g><title>_run (mlprodict/onnxrt/ops_cpu/op_softmax.py:25) (9 samples, 1.33%)</title><rect x="60.3550%" y="196" width="1.3314%" height="15" fill="rgb(243,32,47)"/><text x="60.6050%" y="206.50"></text></g><g><title>PyArray_DTypeFromObjectHelper (common.c:212) (9 samples, 1.33%)</title><rect x="63.7574%" y="324" width="1.3314%" height="15" fill="rgb(247,202,23)"/><text x="64.0074%" y="334.50"></text></g><g><title>PyArray_GetArrayParamsFromObject (ctors.c:1723) (13 samples, 1.92%)</title><rect x="63.4615%" y="276" width="1.9231%" height="15" fill="rgb(219,102,11)"/><text x="63.7115%" y="286.50">P..</text></g><g><title>PyArray_DTypeFromObject (common.c:108) (13 samples, 1.92%)</title><rect x="63.4615%" y="292" width="1.9231%" height="15" fill="rgb(243,110,44)"/><text x="63.7115%" y="302.50">P..</text></g><g><title>PyArray_DTypeFromObjectHelper (common.c:480) (13 samples, 1.92%)</title><rect x="63.4615%" y="308" width="1.9231%" height="15" fill="rgb(222,74,54)"/><text x="63.7115%" y="318.50">P..</text></g><g><title>PyArray_FromAny (ctors.c:1855) (22 samples, 3.25%)</title><rect x="63.4615%" y="260" width="3.2544%" height="15" fill="rgb(216,99,12)"/><text x="63.7115%" y="270.50">PyA..</text></g><g><title>PyArray_GetArrayParamsFromObject (ctors.c:1755) (9 samples, 1.33%)</title><rect x="65.3846%" y="276" width="1.3314%" height="15" fill="rgb(226,22,26)"/><text x="65.6346%" y="286.50"></text></g><g><title>discover_dimensions (ctors.c:884) (7 samples, 1.04%)</title><rect x="65.6805%" y="292" width="1.0355%" height="15" fill="rgb(217,163,10)"/><text x="65.9305%" y="302.50"></text></g><g><title>array_subscript (mapping.c:1539) (34 samples, 5.03%)</title><rect x="63.3136%" y="228" width="5.0296%" height="15" fill="rgb(213,25,53)"/><text x="63.5636%" y="238.50">array_..</text></g><g><title>prepare_index (mapping.c:516) (33 samples, 4.88%)</title><rect x="63.4615%" y="244" width="4.8817%" height="15" fill="rgb(252,105,26)"/><text x="63.7115%" y="254.50">prepar..</text></g><g><title>PyArray_FromAny (ctors.c:1938) (10 samples, 1.48%)</title><rect x="66.8639%" y="260" width="1.4793%" height="15" fill="rgb(220,39,43)"/><text x="67.1139%" y="270.50"></text></g><g><title>PyArray_AssignFromSequence (ctors.c:581) (10 samples, 1.48%)</title><rect x="66.8639%" y="276" width="1.4793%" height="15" fill="rgb(229,68,48)"/><text x="67.1139%" y="286.50"></text></g><g><title>setArrayFromSequence (ctors.c:550) (7 samples, 1.04%)</title><rect x="67.3077%" y="292" width="1.0355%" height="15" fill="rgb(252,8,32)"/><text x="67.5577%" y="302.50"></text></g><g><title>PyArray_SETITEM (ndarraytypes.h:1565) (7 samples, 1.04%)</title><rect x="67.3077%" y="308" width="1.0355%" height="15" fill="rgb(223,20,43)"/><text x="67.5577%" y="318.50"></text></g><g><title>compiled_run (&lt;string&gt;:19) (40 samples, 5.92%)</title><rect x="62.5740%" y="180" width="5.9172%" height="15" fill="rgb(229,81,49)"/><text x="62.8240%" y="190.50">compiled..</text></g><g><title>_run (mlprodict/onnxrt/ops_cpu/op_array_feature_extractor.py:80) (40 samples, 5.92%)</title><rect x="62.5740%" y="196" width="5.9172%" height="15" fill="rgb(236,28,36)"/><text x="62.8240%" y="206.50">_run (ml..</text></g><g><title>_array_feature_extrator (mlprodict/onnxrt/ops_cpu/op_array_feature_extractor.py:37) (35 samples, 5.18%)</title><rect x="63.3136%" y="212" width="5.1775%" height="15" fill="rgb(249,185,26)"/><text x="63.5636%" y="222.50">_array..</text></g><g><title>&lt;module&gt; (bench_MLPClassifier_default_b_cl_1000_50_12_float_.py:61) (223 samples, 32.99%)</title><rect x="36.0947%" y="52" width="32.9882%" height="15" fill="rgb(249,174,33)"/><text x="36.3447%" y="62.50">&lt;module&gt; (bench_MLPClassifier_default_b_cl_1000_50_12..</text></g><g><title>profile_pyrtc (bench_MLPClassifier_default_b_cl_1000_50_12_float_.py:60) (223 samples, 32.99%)</title><rect x="36.0947%" y="68" width="32.9882%" height="15" fill="rgb(233,201,37)"/><text x="36.3447%" y="78.50">profile_pyrtc (bench_MLPClassifier_default_b_cl_1000_..</text></g><g><title>setup_profile (bench_MLPClassifier_default_b_cl_1000_50_12_float_.py:37) (223 samples, 32.99%)</title><rect x="36.0947%" y="84" width="32.9882%" height="15" fill="rgb(221,78,26)"/><text x="36.3447%" y="94.50">setup_profile (bench_MLPClassifier_default_b_cl_1000_..</text></g><g><title>profile (bench_MLPClassifier_default_b_cl_1000_50_12_float_.py:31) (223 samples, 32.99%)</title><rect x="36.0947%" y="100" width="32.9882%" height="15" fill="rgb(250,127,30)"/><text x="36.3447%" y="110.50">profile (bench_MLPClassifier_default_b_cl_1000_50_12_..</text></g><g><title>time_predict (mlprodict/asv_benchmark/common_asv_skl.py:182) (223 samples, 32.99%)</title><rect x="36.0947%" y="116" width="32.9882%" height="15" fill="rgb(230,49,44)"/><text x="36.3447%" y="126.50">time_predict (mlprodict/asv_benchmark/common_asv_skl...</text></g><g><title>&lt;lambda&gt; (mlprodict/asv_benchmark/common_asv_skl.py:232) (223 samples, 32.99%)</title><rect x="36.0947%" y="132" width="32.9882%" height="15" fill="rgb(229,67,23)"/><text x="36.3447%" y="142.50">&lt;lambda&gt; (mlprodict/asv_benchmark/common_asv_skl.py:2..</text></g><g><title>run (mlprodict/onnxrt/onnx_inference.py:442) (223 samples, 32.99%)</title><rect x="36.0947%" y="148" width="32.9882%" height="15" fill="rgb(249,83,47)"/><text x="36.3447%" y="158.50">run (mlprodict/onnxrt/onnx_inference.py:442)</text></g><g><title>_run_sequence_runtime_compiled (mlprodict/onnxrt/onnx_inference.py:160) (223 samples, 32.99%)</title><rect x="36.0947%" y="164" width="32.9882%" height="15" fill="rgb(215,43,3)"/><text x="36.3447%" y="174.50">_run_sequence_runtime_compiled (mlprodict/onnxrt/onnx..</text></g><g><title>mkl_blas_avx_sgemm_kernel_0 (onnxruntime/capi/libmklml_intel.so) (10 samples, 1.48%)</title><rect x="71.1538%" y="212" width="1.4793%" height="15" fill="rgb(238,154,13)"/><text x="71.4038%" y="222.50"></text></g><g><title>onnxruntime::ArgMax&lt;float&gt;::Compute (onnxruntime/capi/onnxruntime_pybind11_state.so) (7 samples, 1.04%)</title><rect x="72.7811%" y="324" width="1.0355%" height="15" fill="rgb(219,56,2)"/><text x="73.0311%" y="334.50"></text></g><g><title>onnxruntime::PrepareForReduce&lt;float&gt; (onnxruntime/capi/onnxruntime_pybind11_state.so) (7 samples, 1.04%)</title><rect x="72.7811%" y="340" width="1.0355%" height="15" fill="rgb(233,0,4)"/><text x="73.0311%" y="350.50"></text></g><g><title>__kmpc_fork_call (libiomp5.so) (22 samples, 3.25%)</title><rect x="76.7751%" y="420" width="3.2544%" height="15" fill="rgb(235,30,7)"/><text x="77.0251%" y="430.50">__k..</text></g><g><title>__kmp_join_call (libiomp5.so) (16 samples, 2.37%)</title><rect x="77.6627%" y="436" width="2.3669%" height="15" fill="rgb(250,79,13)"/><text x="77.9127%" y="446.50">__..</text></g><g><title>__kmp_internal_join (libiomp5.so) (16 samples, 2.37%)</title><rect x="77.6627%" y="452" width="2.3669%" height="15" fill="rgb(211,146,34)"/><text x="77.9127%" y="462.50">__..</text></g><g><title>__kmp_join_barrier (libiomp5.so) (16 samples, 2.37%)</title><rect x="77.6627%" y="468" width="2.3669%" height="15" fill="rgb(228,22,38)"/><text x="77.9127%" y="478.50">__..</text></g><g><title>_INTERNAL_25_______src_kmp_barrier_cpp_50ae66a0::__kmp_hyper_barrier_gather (libiomp5.so) (16 samples, 2.37%)</title><rect x="77.6627%" y="484" width="2.3669%" height="15" fill="rgb(235,168,5)"/><text x="77.9127%" y="494.50">_I..</text></g><g><title>onnxruntime::Gemm&lt;float&gt;::Compute (onnxruntime/capi/onnxruntime_pybind11_state.so) (49 samples, 7.25%)</title><rect x="75.7396%" y="324" width="7.2485%" height="15" fill="rgb(221,155,16)"/><text x="75.9896%" y="334.50">onnxruntim..</text></g><g><title>onnxruntime::math::Gemm&lt;float, onnxruntime::concurrency::ThreadPool&gt; (onnxruntime/capi/onnxruntime_pybind11_state.so) (43 samples, 6.36%)</title><rect x="76.6272%" y="340" width="6.3609%" height="15" fill="rgb(215,215,53)"/><text x="76.8772%" y="350.50">onnxrunt..</text></g><g><title>cblas_sgemm (onnxruntime/capi/libmklml_intel.so) (43 samples, 6.36%)</title><rect x="76.6272%" y="356" width="6.3609%" height="15" fill="rgb(223,4,10)"/><text x="76.8772%" y="366.50">cblas_sg..</text></g><g><title>sgemm_ (onnxruntime/capi/libmklml_intel.so) (43 samples, 6.36%)</title><rect x="76.6272%" y="372" width="6.3609%" height="15" fill="rgb(234,103,6)"/><text x="76.8772%" y="382.50">sgemm_ (..</text></g><g><title>mkl_blas_sgemm (onnxruntime/capi/libmklml_intel.so) (43 samples, 6.36%)</title><rect x="76.6272%" y="388" width="6.3609%" height="15" fill="rgb(227,97,0)"/><text x="76.8772%" y="398.50">mkl_blas..</text></g><g><title>mkl_blas_sgemm_omp_driver_v1 (onnxruntime/capi/libmklml_intel.so) (43 samples, 6.36%)</title><rect x="76.6272%" y="404" width="6.3609%" height="15" fill="rgb(234,150,53)"/><text x="76.8772%" y="414.50">mkl_blas..</text></g><g><title>mkl_blas_xsgemm (onnxruntime/capi/libmklml_intel.so) (20 samples, 2.96%)</title><rect x="80.0296%" y="420" width="2.9586%" height="15" fill="rgb(228,201,54)"/><text x="80.2796%" y="430.50">mkl..</text></g><g><title>mkl_blas_avx_xsgemm (onnxruntime/capi/libmklml_intel.so) (20 samples, 2.96%)</title><rect x="80.0296%" y="436" width="2.9586%" height="15" fill="rgb(222,22,37)"/><text x="80.2796%" y="446.50">mkl..</text></g><g><title>mkl_blas_avx_sgemm_pst (onnxruntime/capi/libmklml_intel.so) (20 samples, 2.96%)</title><rect x="80.0296%" y="452" width="2.9586%" height="15" fill="rgb(237,53,32)"/><text x="80.2796%" y="462.50">mkl..</text></g><g><title>Eigen::ThreadPoolDevice::parallelFor (onnxruntime/capi/onnxruntime_pybind11_state.so) (7 samples, 1.04%)</title><rect x="82.9882%" y="356" width="1.0355%" height="15" fill="rgb(233,25,53)"/><text x="83.2382%" y="366.50"></text></g><g><title>Eigen::ThreadPoolDevice::parallelFor (onnxruntime/capi/onnxruntime_pybind11_state.so) (7 samples, 1.04%)</title><rect x="82.9882%" y="372" width="1.0355%" height="15" fill="rgb(210,40,34)"/><text x="83.2382%" y="382.50"></text></g><g><title>_ZNSt17_Function_handlerIFvllEZN5Eigen8internal14TensorExecutorIKNS1_14TensorAssignOpINS1_9TensorMapINS1_6TensorIfLi2ELi1ElEELi16ENS1_11MakePointerEEEKNS1_18TensorCwiseUnaryOpINS2_13scalar_exp_opIfEEKNS1_19TensorCwiseBinaryOpINS2_20scalar_difference_opIKfSF_EEKNS5_INS6_ISF_Li2ELi1ElEELi16ES8_EEKNS1_20TensorBroadcastingOpIKNS1_9IndexListINS1_10type2indexILl1EEEJiEEEKNS1_17TensorReshapingOpIKNSL_IiJSN_EEEKNS1_18TensorForcedEvalOpIKNS1_17TensorReductionOpINS2_10MaxReducerIfEEKNSL_ISN_JEEESJ_S8_EEEEEEEEEEEEEENS1_16ThreadPoolDeviceELb1ELb1EE3runERS1C_RKS1D_EUlllE_E9_M_invokeERKSt9_Any_dataOlS1N_ (onnxruntime/capi/onnxruntime_pybind11_state.so) (7 samples, 1.04%)</title><rect x="82.9882%" y="388" width="1.0355%" height="15" fill="rgb(241,220,44)"/><text x="83.2382%" y="398.50"></text></g><g><title>onnxruntime::Softmax&lt;float, false&gt;::Compute (onnxruntime/capi/onnxruntime_pybind11_state.so) (13 samples, 1.92%)</title><rect x="82.9882%" y="324" width="1.9231%" height="15" fill="rgb(235,28,35)"/><text x="83.2382%" y="334.50">o..</text></g><g><title>onnxruntime::ComputeSoftMax&lt;Eigen::ThreadPoolDevice, float&gt; [clone .constprop.656] (onnxruntime/capi/onnxruntime_pybind11_state.so) (13 samples, 1.92%)</title><rect x="82.9882%" y="340" width="1.9231%" height="15" fill="rgb(210,56,17)"/><text x="83.2382%" y="350.50">o..</text></g><g><title>operator new (libstdc++.so.6.0.28) (38 samples, 5.62%)</title><rect x="85.7988%" y="340" width="5.6213%" height="15" fill="rgb(224,130,29)"/><text x="86.0488%" y="350.50">operato..</text></g><g><title>malloc (libc-2.29.so) (37 samples, 5.47%)</title><rect x="85.9467%" y="356" width="5.4734%" height="15" fill="rgb(235,212,8)"/><text x="86.1967%" y="366.50">malloc ..</text></g><g><title>onnxruntime::InferenceSession::Run (onnxruntime/capi/onnxruntime_pybind11_state.so) (131 samples, 19.38%)</title><rect x="72.7811%" y="244" width="19.3787%" height="15" fill="rgb(223,33,50)"/><text x="73.0311%" y="254.50">onnxruntime::InferenceSession:..</text></g><g><title>onnxruntime::InferenceSession::Run (onnxruntime/capi/onnxruntime_pybind11_state.so) (131 samples, 19.38%)</title><rect x="72.7811%" y="260" width="19.3787%" height="15" fill="rgb(219,149,13)"/><text x="73.0311%" y="270.50">onnxruntime::InferenceSession:..</text></g><g><title>onnxruntime::utils::ExecuteGraph (onnxruntime/capi/onnxruntime_pybind11_state.so) (131 samples, 19.38%)</title><rect x="72.7811%" y="276" width="19.3787%" height="15" fill="rgb(250,156,29)"/><text x="73.0311%" y="286.50">onnxruntime::utils::ExecuteGra..</text></g><g><title>onnxruntime::utils::ExecuteGraphImpl (onnxruntime/capi/onnxruntime_pybind11_state.so) (131 samples, 19.38%)</title><rect x="72.7811%" y="292" width="19.3787%" height="15" fill="rgb(216,193,19)"/><text x="73.0311%" y="302.50">onnxruntime::utils::ExecuteGra..</text></g><g><title>onnxruntime::SequentialExecutor::Execute (onnxruntime/capi/onnxruntime_pybind11_state.so) (131 samples, 19.38%)</title><rect x="72.7811%" y="308" width="19.3787%" height="15" fill="rgb(216,135,14)"/><text x="73.0311%" y="318.50">onnxruntime::SequentialExecuto..</text></g><g><title>onnxruntime::ml::ZipMapOp::Compute (onnxruntime/capi/onnxruntime_pybind11_state.so) (49 samples, 7.25%)</title><rect x="84.9112%" y="324" width="7.2485%" height="15" fill="rgb(241,47,5)"/><text x="85.1612%" y="334.50">onnxruntim..</text></g><g><title>onnxruntime::NonTensorType&lt;std::vector&lt;std::map&lt;long, float, std::less&lt;long&gt;, std::allocator&lt;std::pair&lt;long const, float&gt; &gt; &gt;, std::allocator&lt;std::map&lt;long, float, std::less&lt;long&gt;, std::allocator&lt;std::pair&lt;long const, float&gt; &gt; &gt; &gt; &gt; &gt;::Delete (onnxruntime/capi/onnxruntime_pybind11_state.so) (12 samples, 1.78%)</title><rect x="92.1598%" y="244" width="1.7751%" height="15" fill="rgb(233,42,35)"/><text x="92.4098%" y="254.50">o..</text></g><g><title>std::_Rb_tree&lt;long, std::pair&lt;long const, float&gt;, std::_Select1st&lt;std::pair&lt;long const, float&gt; &gt;, std::less&lt;long&gt;, std::allocator&lt;std::pair&lt;long const, float&gt; &gt; &gt;::_M_erase (onnxruntime/capi/onnxruntime_pybind11_state.so) (8 samples, 1.18%)</title><rect x="92.7515%" y="260" width="1.1834%" height="15" fill="rgb(231,13,6)"/><text x="93.0015%" y="270.50"></text></g><g><title>onnxruntime::python::AddNonTensorAsPyObj (onnxruntime/capi/onnxruntime_pybind11_state.so) (35 samples, 5.18%)</title><rect x="93.9349%" y="244" width="5.1775%" height="15" fill="rgb(207,181,40)"/><text x="94.1849%" y="254.50">onnxru..</text></g><g><title>onnxruntime::python::AddNonTensor&lt;std::vector&lt;std::map&lt;long, float, std::less&lt;long&gt;, std::allocator&lt;std::pair&lt;long const, float&gt; &gt; &gt;, std::allocator&lt;std::map&lt;long, float, std::less&lt;long&gt;, std::allocator&lt;std::pair&lt;long const, float&gt; &gt; &gt; &gt; &gt; &gt; (onnxruntime/capi/onnxruntime_pybind11_state.so) (35 samples, 5.18%)</title><rect x="93.9349%" y="260" width="5.1775%" height="15" fill="rgb(254,173,49)"/><text x="94.1849%" y="270.50">onnxru..</text></g><g><title>pybind11::detail::map_caster&lt;std::map&lt;long, float, std::less&lt;long&gt;, std::allocator&lt;std::pair&lt;long const, float&gt; &gt; &gt;, long, float&gt;::cast&lt;std::map&lt;long, float, std::less&lt;long&gt;, std::allocator&lt;std::pair&lt;long const, float&gt; &gt; &gt; const&amp;&gt; (onnxruntime/capi/onnxruntime_pybind11_state.so) (34 samples, 5.03%)</title><rect x="94.0828%" y="276" width="5.0296%" height="15" fill="rgb(221,1,38)"/><text x="94.3328%" y="286.50">pybind..</text></g><g><title>pybind11::dict::dict (onnxruntime/capi/onnxruntime_pybind11_state.so) (11 samples, 1.63%)</title><rect x="97.4852%" y="292" width="1.6272%" height="15" fill="rgb(206,124,46)"/><text x="97.7352%" y="302.50"></text></g><g><title>_run_whole_runtime (mlprodict/onnxrt/onnx_inference.py:650) (193 samples, 28.55%)</title><rect x="71.0059%" y="164" width="28.5503%" height="15" fill="rgb(249,21,11)"/><text x="71.2559%" y="174.50">_run_whole_runtime (mlprodict/onnxrt/onnx_infe..</text></g><g><title>run (mlprodict/onnxrt/ops_whole/session.py:64) (193 samples, 28.55%)</title><rect x="71.0059%" y="180" width="28.5503%" height="15" fill="rgb(222,201,40)"/><text x="71.2559%" y="190.50">run (mlprodict/onnxrt/ops_whole/session.py:64)</text></g><g><title>run (onnxruntime/capi/session.py:142) (193 samples, 28.55%)</title><rect x="71.0059%" y="196" width="28.5503%" height="15" fill="rgb(235,61,29)"/><text x="71.2559%" y="206.50">run (onnxruntime/capi/session.py:142)</text></g><g><title>pybind11::cpp_function::dispatcher (onnxruntime/capi/onnxruntime_pybind11_state.so) (182 samples, 26.92%)</title><rect x="72.6331%" y="212" width="26.9231%" height="15" fill="rgb(219,207,3)"/><text x="72.8831%" y="222.50">pybind11::cpp_function::dispatcher (onnxrun..</text></g><g><title>void pybind11::cpp_function::initialize&lt;onnxruntime::python::addObjectMethods(pybind11::module&amp;)::{lambda(onnxruntime::InferenceSession*, std::vector&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, std::allocator&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt; &gt;, std::map&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, pybind11::object, std::less&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt;, std::allocator&lt;std::pair&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const, pybind11::object&gt; &gt; &gt;, OrtRunOptions*)#8}, std::vector&lt;pybind11::object, std::allocator&lt;pybind11::object&gt; &gt;, onnxruntime::InferenceSession*, std::vector&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, std::allocator&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt; &gt;, std::map&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, pybind11::object, std::less&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt;, std::allocator&lt;std::pair&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const, pybind11::object&gt; &gt; &gt;, OrtRunOptions*, pybind11::name, pybind11::is_method, pybind11::sibling&gt;(onnxruntime::python::addObjectMethods(pybind11::module&amp;)::{lambda(onnxruntime::InferenceSession*, std::vector&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, std::allocator&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt; &gt;, std::map&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, pybind11::object, std::less&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt;, std::allocator&lt;std::pair&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const, pybind11::object&gt; &gt; &gt;, OrtRunOptions*)#8}&amp;&amp;, std::vector&lt;pybind11::object, std::allocator&lt;pybind11::object&gt; &gt; (*)(onnxruntime::InferenceSession*, std::vector&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, std::allocator&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt; &gt;, std::map&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, pybind11::object, std::less&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt;, std::allocator&lt;std::pair&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const, pybind11::object&gt; &gt; &gt;, OrtRunOptions*), pybind11::name const, pybind11::is_method&amp;, pybind11::sibling)::{lambda(pybind11::detail::function_call&amp;)#3}::_FUN (onnxruntime/capi/onnxruntime_pybind11_state.so) (182 samples, 26.92%)</title><rect x="72.6331%" y="228" width="26.9231%" height="15" fill="rgb(222,56,46)"/><text x="72.8831%" y="238.50">void pybind11::cpp_function::initialize&lt;onn..</text></g><g><title>all (676 samples, 100%)</title><rect x="0.0000%" y="36" width="100.0000%" height="15" fill="rgb(239,76,54)"/><text x="0.2500%" y="46.50"></text></g><g><title>&lt;module&gt; (bench_MLPClassifier_default_b_cl_1000_50_12_float_.py:68) (209 samples, 30.92%)</title><rect x="69.0828%" y="52" width="30.9172%" height="15" fill="rgb(231,124,27)"/><text x="69.3328%" y="62.50">&lt;module&gt; (bench_MLPClassifier_default_b_cl_1000_50..</text></g><g><title>profile_ort (bench_MLPClassifier_default_b_cl_1000_50_12_float_.py:67) (209 samples, 30.92%)</title><rect x="69.0828%" y="68" width="30.9172%" height="15" fill="rgb(249,195,6)"/><text x="69.3328%" y="78.50">profile_ort (bench_MLPClassifier_default_b_cl_1000..</text></g><g><title>setup_profile (bench_MLPClassifier_default_b_cl_1000_50_12_float_.py:37) (207 samples, 30.62%)</title><rect x="69.3787%" y="84" width="30.6213%" height="15" fill="rgb(237,174,47)"/><text x="69.6287%" y="94.50">setup_profile (bench_MLPClassifier_default_b_cl_1..</text></g><g><title>profile (bench_MLPClassifier_default_b_cl_1000_50_12_float_.py:31) (207 samples, 30.62%)</title><rect x="69.3787%" y="100" width="30.6213%" height="15" fill="rgb(206,201,31)"/><text x="69.6287%" y="110.50">profile (bench_MLPClassifier_default_b_cl_1000_50..</text></g><g><title>time_predict (mlprodict/asv_benchmark/common_asv_skl.py:182) (196 samples, 28.99%)</title><rect x="71.0059%" y="116" width="28.9941%" height="15" fill="rgb(231,57,52)"/><text x="71.2559%" y="126.50">time_predict (mlprodict/asv_benchmark/common_as..</text></g><g><title>&lt;lambda&gt; (mlprodict/asv_benchmark/common_asv_skl.py:232) (196 samples, 28.99%)</title><rect x="71.0059%" y="132" width="28.9941%" height="15" fill="rgb(248,177,22)"/><text x="71.2559%" y="142.50">&lt;lambda&gt; (mlprodict/asv_benchmark/common_asv_sk..</text></g><g><title>run (mlprodict/onnxrt/onnx_inference.py:442) (196 samples, 28.99%)</title><rect x="71.0059%" y="148" width="28.9941%" height="15" fill="rgb(215,211,37)"/><text x="71.2559%" y="158.50">run (mlprodict/onnxrt/onnx_inference.py:442)</text></g></svg></svg>